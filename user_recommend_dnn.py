from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
import pyodbc
import itertools

# ğŸš€ Káº¿t ná»‘i cÆ¡ sá»Ÿ dá»¯ liá»‡u
conn = pyodbc.connect(
    'DRIVER={ODBC Driver 17 for SQL Server};'
    'SERVER=LAPTOP-0SMFMLRQ;'
    'DATABASE=CourseAI;'
    'UID=test;'
    'PWD=1234'
)

# ğŸš€ Truy váº¥n dá»¯ liá»‡u ngÆ°á»i dÃ¹ng vÃ  khÃ³a há»c
query = "SELECT UserId, CourseId, EnrollmentStatus FROM dbo.UserCourses"
df_enrollments = pd.read_sql(query, conn)
conn.close()

# ğŸš€ Äáº·t EnrollmentStatus cho khÃ³a há»c chÆ°a Ä‘Äƒng kÃ½ lÃ  0
df_enrollments['EnrollmentStatus'] = df_enrollments['EnrollmentStatus'].fillna(0).apply(lambda x: 1 if x == 2 else 0)

# ğŸš€ MÃ£ hÃ³a UserId vÃ  CourseId
user_encoder = LabelEncoder()
course_encoder = LabelEncoder()

df_enrollments['UserId'] = user_encoder.fit_transform(df_enrollments['UserId'])
df_enrollments['CourseId'] = course_encoder.fit_transform(df_enrollments['CourseId'])

# ğŸš€ Táº¡o táº¥t cáº£ káº¿t há»£p UserId - CourseId (bao gá»“m cáº£ cÃ¡c khÃ³a há»c chÆ°a Ä‘Äƒng kÃ½)
all_users = df_enrollments['UserId'].unique()
all_courses = df_enrollments['CourseId'].unique()
all_combinations = pd.DataFrame(list(itertools.product(all_users, all_courses)), columns=['UserId', 'CourseId'])

# ğŸš€ GÃ¡n tráº¡ng thÃ¡i Ä‘Äƒng kÃ½ cho cÃ¡c khÃ³a há»c (0 cho khÃ³a há»c chÆ°a Ä‘Äƒng kÃ½)
df = pd.merge(all_combinations, df_enrollments[['UserId', 'CourseId', 'EnrollmentStatus']],
              on=['UserId', 'CourseId'], how='left')
df['EnrollmentStatus'] = df['EnrollmentStatus'].fillna(0)

# ğŸš€ Äá»‹nh dáº¡ng láº¡i cá»™t dá»¯ liá»‡u
X = df[['UserId', 'CourseId']]
y = df['EnrollmentStatus']

# ğŸš€ Chuáº©n hÃ³a dá»¯ liá»‡u
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ğŸš€ Chia dá»¯ liá»‡u
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)


# Táº¡o ma tráº­n UserId x CourseId
df_pivot = df.pivot(index='UserId', columns='CourseId', values='EnrollmentStatus')

# Xuáº¥t ma tráº­n ra file CSV
df_pivot.to_csv('user_course_matrix.csv', index=True)

# ğŸš€ XÃ¢y dá»±ng mÃ´ hÃ¬nh DNN (tá»‘i Æ°u)
model = tf.keras.models.Sequential([
    tf.keras.layers.InputLayer(input_shape=(2,)),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# ğŸš€ Huáº¥n luyá»‡n mÃ´ hÃ¬nh
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)

history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_split=0.2,
    callbacks=[early_stopping, reduce_lr]
)

# ğŸš€ ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Äá»™ chÃ­nh xÃ¡c mÃ´ hÃ¬nh: {accuracy:.2f}")

# ğŸš€ HÃ m gá»£i Ã½ khÃ³a há»c cho ngÆ°á»i dÃ¹ng
def recommend_courses_dnn(user_id, top_n=5):
    # Kiá»ƒm tra náº¿u user_id khÃ´ng tá»“n táº¡i
    if user_id not in user_encoder.classes_:
        raise ValueError("UserId khÃ´ng tá»“n táº¡i trong dá»¯ liá»‡u.")

    # MÃ£ hÃ³a user_id
    user_encoded = user_encoder.transform([user_id])[0]

    # ğŸš€ Láº¥y khÃ³a há»c mÃ  ngÆ°á»i dÃ¹ng Ä‘Ã£ thá»±c sá»± Ä‘Äƒng kÃ½
    courses_user_registered = df[(df['UserId'] == user_encoded) & (df['EnrollmentStatus'] == 1)]['CourseId'].unique()
    all_courses_encoded = df['CourseId'].unique()

    # KhÃ³a há»c chÆ°a Ä‘Äƒng kÃ½
    courses_not_registered = np.setdiff1d(all_courses_encoded, courses_user_registered)

    # Kiá»ƒm tra náº¿u khÃ´ng cÃ²n khÃ³a há»c nÃ o Ä‘á»ƒ gá»£i Ã½
    if len(courses_not_registered) == 0:
        return "NgÆ°á»i dÃ¹ng Ä‘Ã£ Ä‘Äƒng kÃ½ táº¥t cáº£ cÃ¡c khÃ³a há»c. KhÃ´ng cÃ²n khÃ³a há»c nÃ o Ä‘á»ƒ gá»£i Ã½."

    # Dá»± Ä‘oÃ¡n cho khÃ³a há»c chÆ°a Ä‘Äƒng kÃ½
    inputs = np.array([[user_encoded, course] for course in courses_not_registered])
    inputs_scaled = scaler.transform(inputs)
    predictions = model.predict(inputs_scaled).flatten()

    # Láº¥y top N khÃ³a há»c gá»£i Ã½
    top_courses_indices = np.argsort(-predictions)[:top_n]
    top_courses = courses_not_registered[top_courses_indices]
    recommended_courses = course_encoder.inverse_transform(top_courses)

    return recommended_courses.tolist()

# ğŸš€ VÃ­ dá»¥: Gá»£i Ã½ khÃ³a há»c cho User cÃ³ ID = 'E859E761-C879-4422-BDDB-06999875DF33'
user_example = 'E859E761-C879-4422-BDDB-06999875DF33'

# ğŸš€ Kiá»ƒm tra UserId
try:
    recommended = recommend_courses_dnn(user_example)
    print("Gá»£i Ã½ khÃ³a há»c (DNN) cho", user_example, ":", recommended)
except ValueError as e:
    print(e)

